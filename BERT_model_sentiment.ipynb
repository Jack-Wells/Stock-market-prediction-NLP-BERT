{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "BERT model sentiment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5034a369a4ff44d2b9761d5130ae32ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5878da4489ae4bf7ac268087be71611d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a84dcf17e252471faa698c05455f3fab",
              "IPY_MODEL_9909c7d8881d4153ad16884250fca53c"
            ]
          }
        },
        "5878da4489ae4bf7ac268087be71611d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a84dcf17e252471faa698c05455f3fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f698124db00b4e50a9175d75d25598b1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a6bbfba977d4699804537923be80c71"
          }
        },
        "9909c7d8881d4153ad16884250fca53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_701734365ba54ea592102dba2899d155",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 299kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a552b26ec7c43ddac22de8b8f1da4f8"
          }
        },
        "f698124db00b4e50a9175d75d25598b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a6bbfba977d4699804537923be80c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "701734365ba54ea592102dba2899d155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a552b26ec7c43ddac22de8b8f1da4f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d014dd1861664a8699e8349fd778585c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_776bede1fce4459aa9bbe05c76a93634",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c035c3d891174737ad1f41171aa79555",
              "IPY_MODEL_acad3ef1689847e2b462239623585371"
            ]
          }
        },
        "776bede1fce4459aa9bbe05c76a93634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c035c3d891174737ad1f41171aa79555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8fff9d1960594d6584f92211d329ec71",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ba9d13ce49d4860897ccbfa2ddc0183"
          }
        },
        "acad3ef1689847e2b462239623585371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0bdaa2aac87d40e5a0623349d3f437f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.14kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc515bca4643494cbfb7356ef37b4b91"
          }
        },
        "8fff9d1960594d6584f92211d329ec71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ba9d13ce49d4860897ccbfa2ddc0183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bdaa2aac87d40e5a0623349d3f437f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc515bca4643494cbfb7356ef37b4b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afb2a84a9d5a4a6e98ea4fcf8f41aa6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aa7723a59d5f461a9f884097395e5bfc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_77e50e5f462f4a60b9b43abbb5d9e678",
              "IPY_MODEL_832a4ed2d48d481fb9eb2bd3ac1c04d4"
            ]
          }
        },
        "aa7723a59d5f461a9f884097395e5bfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77e50e5f462f4a60b9b43abbb5d9e678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3c2a6dd154924d23ae1dc446e96c3a96",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68c1bbb867c54d109b561f664a368d35"
          }
        },
        "832a4ed2d48d481fb9eb2bd3ac1c04d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b031b41ae48540928f9fcc8edb4678f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:13&lt;00:00, 32.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b9d0a76d54c4cc6b77506351cf3f133"
          }
        },
        "3c2a6dd154924d23ae1dc446e96c3a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68c1bbb867c54d109b561f664a368d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b031b41ae48540928f9fcc8edb4678f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b9d0a76d54c4cc6b77506351cf3f133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRTfrWzhn_2_",
        "colab_type": "text"
      },
      "source": [
        "# Text analysis for stock market prediction\n",
        "\n",
        "In this part of my project I use the pre-trained BERT model to analyse the sentiment of over 48000 news articles that I have collected. To do this I train the BERT model on a set of approximately 5000 sentiment labelled stock market news articles. I will then use this fine tuned model to predict the sentiment on my articles.\n",
        "\n",
        "<br>\n",
        "\n",
        "This model is 85% accurate at understanding the sentiment of news articles\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBkirR8qMRhj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "bcbd04ba-5a45-4315-ab71-11dd47b66bde"
      },
      "source": [
        "import re \n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c6wlqqbM3qf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "4891bc7e-7830-446d-e597-858a74ac7113"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGRt_nG0MRh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "92264717-c6a3-4ec7-bc82-90f8e878507f"
      },
      "source": [
        "file = open('drive/My Drive/text.csv','r',encoding='UTF-8')\n",
        "File = open('drive/My Drive/stocks_name.txt','r')\n",
        "\n",
        "Name = []\n",
        "Codes = []\n",
        "Type = []\n",
        "Add = []\n",
        "\n",
        "for line in File:\n",
        "    line = re.sub('\\n', '', line)\n",
        "    line = line.split('\\t')\n",
        "    Name.append(re.sub(' ', ' ',line[0].lower())+' ')\n",
        "    Type.append(line[2])\n",
        "    Add.append(line[1].lower()+ ' ')\n",
        "    if line[1][2:4] == '.A':\n",
        "        Codes.append('BT-A.L')\n",
        "    elif line[1][2] == '.':\n",
        "        Codes.append(line[1] + 'L')\n",
        "    else:\n",
        "        Codes.append(line[1] + '.L')\n",
        "\n",
        "a=0\n",
        "le = 0\n",
        "for line in file:\n",
        "    line = line.split(']')\n",
        "    #print(line)\n",
        "    #print(len(line))\n",
        "    a+=len(line)\n",
        "    le += 1\n",
        "    if le == 3:\n",
        "        h = line\n",
        "\n",
        "print(le)\n",
        "    \n",
        "print('Total number of articles : ', a)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99\n",
            "Total number of articles :  48631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-scB9MBjnUbX",
        "colab_type": "text"
      },
      "source": [
        "This is builds a collection of very specific words that are hard to train on so they will be replaced with the word company. This will hopefully produce better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21j-jE12MRiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "afb1baca-b44d-4a83-a55c-019ea51bc8d9"
      },
      "source": [
        "A = ['admiral ','anglo american ','ashtead ' ,'auto trader ','bae ','barratt ','berkeley ','berkeley group ','american tobacco ',\n",
        "     'british tobacco ','bt ','carnival corporation ','coca cola ','cola ','coke ','cocacola ','compass ','crh ','croda ','dcc ','ferguson ',\n",
        "    'flutter ','intercontinental hotels ','hargreaves ','lansdown ','hikma ','international airlines ','airlines group ','itv ','jd ',\n",
        "     'kingfisher ','legal general ','lloyds ','lloyds banking ','lse ','london stock exchange ','mg ','melrose ','national grid ','nmc ',\n",
        "     'pearson ','persimmon ','pheonix ','polymetal ','predential ','reckitt ','benckiser ','rentokil ','rio tinto ','rolls royce ','rolls-royce ',\n",
        "    'rollsroyce ','rbs ','bank of scotland ','shell ','dutch shell ','rsa ','rsa insurance ','sage ','sainsburys ','scottish mortgage investment ',\n",
        "    'scottish mortgage ','smith nephew ','smith ','smiths ','ds ','smurfit ','kappa ','pirax sarco ','pirax sarco engineering ','sse ',\n",
        "    'standard life ','st jamess ','st james ','st. jamess place ','st. james place ','taylor ','wimpey ','tui ','vodafone ','wpp ','3is ']\n",
        "As = []\n",
        "for word in A:\n",
        "    As.append(word[:-1]+'s ')\n",
        "Name = Name + A + Add + As\n",
        "print(len(Name))\n",
        "#need plural of all above"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XwUaGhZoymE",
        "colab_type": "text"
      },
      "source": [
        "This part of the code generates a label for each of the news articles collected for the companies in the FTSE 100 based on how the stock price changed between the morning of the article being posted and the close 2 days later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jdl5-YCOMRi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41cf14d6-5026-4ead-a964-770b4aa816a3"
      },
      "source": [
        "file = open('drive/My Drive/text.csv','r',encoding='UTF-8')\n",
        "\n",
        "DataFrame = pd.DataFrame()\n",
        "\n",
        "a=0\n",
        "le = 0\n",
        "\n",
        "for line in file:\n",
        "    line = line.split(']')\n",
        "    le += 1\n",
        "        \n",
        "    sentence = []\n",
        "    date = []\n",
        "\n",
        "    for i in line:\n",
        "        i = i.split('xa0')\n",
        "        s=re.sub(r'-', ' ',i[0].lower())\n",
        "        s=re.sub(r'[^a-z ]', '', s) #removing number doesnt do much to improve \n",
        "        s=re.sub('ftse 100','shares',s)\n",
        "        s=re.sub('ftse','shares',s)\n",
        "        s=re.sub('investingcom united kingdom','',s)\n",
        "\n",
        "        big_regex = re.compile('|'.join(map(re.escape, Name))) #removes the company names\n",
        "        s = big_regex.sub(\"company \", s)\n",
        "\n",
        "        words = s.split()\n",
        "        words = [word for word in words if word not in stop_words] #removes stop words\n",
        "        content = ' '.join([lemmatizer.lemmatize(word) for word in words]) #reduces every word to its stem\n",
        "        sentence.append(content)\n",
        "\n",
        "        try:\n",
        "            dat = re.sub(r'[^A-Za-z0-9 ]', '', i[-1])\n",
        "            dat = re.sub(' ', '-', dat)\n",
        "            dat = datetime.datetime.strptime(dat, '%b-%d-%Y')\n",
        "            date.append(dat)\n",
        "        except:\n",
        "            dat = '27-03-2020'\n",
        "            dat = datetime.datetime.strptime(dat, '%d-%m-%Y')\n",
        "            date.append(dat)\n",
        "\n",
        "    if len(date) != len(sentence):\n",
        "        print(le)\n",
        "        break\n",
        "        \n",
        "    sentence = sentence[:-2]\n",
        "    date = date[:-2]\n",
        "\n",
        "    dF = pd.DataFrame(date)\n",
        "    dF.columns = ['Date']\n",
        "    dF['sent'] = sentence\n",
        "    dF = dF.sort_values('Date')\n",
        "    dF.set_index('Date', inplace=True)\n",
        "\n",
        "    DF = pd.read_csv('drive/My Drive/csv/' + Codes[le-1] + '.csv')\n",
        "\n",
        "    # Sort DataFrame by date\n",
        "    DF = DF.sort_values('Date')\n",
        "    DF.set_index('Date', inplace=True)\n",
        "    \n",
        "    delay = 2\n",
        "    percent = []\n",
        "    for i in range(len(DF['Close'])-delay):\n",
        "        percent.append((DF['Close'][i+delay] - DF['Open'][i])/DF['Open'][i])\n",
        "        \n",
        "    for i in range(len(DF['Close'])-len(percent)):\n",
        "        percent.append(0)\n",
        "        \n",
        "    DF['percent'] = percent\n",
        "\n",
        "    data = pd.merge(DF,dF, how='right', left_index=True, right_index=True)\n",
        "    data = data.fillna(0)\n",
        "    data = data.drop(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], axis=1)\n",
        "    #print(data.tail(10))\n",
        "    \n",
        "    DataFrame = DataFrame.append(data)\n",
        "    print(len(DataFrame))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104\n",
            "244\n",
            "1389\n",
            "1894\n",
            "2110\n",
            "2435\n",
            "3274\n",
            "3301\n",
            "3334\n",
            "3361\n",
            "3933\n",
            "4437\n",
            "8424\n",
            "8867\n",
            "9036\n",
            "9914\n",
            "12303\n",
            "12908\n",
            "13005\n",
            "13508\n",
            "13620\n",
            "14013\n",
            "14490\n",
            "15056\n",
            "15202\n",
            "15344\n",
            "15523\n",
            "15556\n",
            "15625\n",
            "16106\n",
            "17038\n",
            "17069\n",
            "17142\n",
            "17289\n",
            "17456\n",
            "18040\n",
            "19399\n",
            "19434\n",
            "20014\n",
            "21931\n",
            "22226\n",
            "22673\n",
            "22727\n",
            "22918\n",
            "24130\n",
            "24201\n",
            "24895\n",
            "24980\n",
            "25113\n",
            "25165\n",
            "25515\n",
            "25606\n",
            "25864\n",
            "27668\n",
            "28237\n",
            "28277\n",
            "28409\n",
            "28483\n",
            "28639\n",
            "29139\n",
            "29502\n",
            "29799\n",
            "30081\n",
            "30489\n",
            "31192\n",
            "31713\n",
            "31781\n",
            "31972\n",
            "32785\n",
            "33059\n",
            "33142\n",
            "33208\n",
            "34198\n",
            "34928\n",
            "36875\n",
            "39453\n",
            "39610\n",
            "39743\n",
            "40376\n",
            "40644\n",
            "40663\n",
            "40691\n",
            "40827\n",
            "40987\n",
            "41087\n",
            "41141\n",
            "41169\n",
            "41679\n",
            "42857\n",
            "43319\n",
            "43414\n",
            "43858\n",
            "45437\n",
            "45765\n",
            "46651\n",
            "46776\n",
            "47703\n",
            "47968\n",
            "48433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L67KTcHgpNB1",
        "colab_type": "text"
      },
      "source": [
        "For future testing I combine the data from the most recent 10 news articles to build up a better picture of the company."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl8kT_qfMRjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trial = DataFrame\n",
        "trial.tail()\n",
        "percent = trial['percent']\n",
        "\n",
        "binary = []\n",
        "for p in percent:\n",
        "    if p < 0:\n",
        "        binary.append(0)\n",
        "    else:\n",
        "        binary.append(1)\n",
        "\n",
        "sent = trial['sent']\n",
        "\n",
        "trial = trial.drop(columns = ['percent'])\n",
        "trial['binary'] = binary\n",
        "\n",
        "trial.head()\n",
        "\n",
        "articles = 10\n",
        "\n",
        "full = []\n",
        "new_sent = []\n",
        "for i in range(len(list(sent))):\n",
        "    \n",
        "    if sent[i] != 0:\n",
        "        new_sent.append(sent[i])        \n",
        "      \n",
        "    if len(new_sent) == 0:\n",
        "        full.append(0)\n",
        "    elif len(new_sent) > articles:\n",
        "        new_sent = new_sent[-articles:]\n",
        "        full.append(new_sent)\n",
        "    else:\n",
        "        full.append(new_sent)\n",
        "    \n",
        "\n",
        "\n",
        "Full = []\n",
        "for f in full:\n",
        "    string = str(f)\n",
        "    Full.append(re.sub(r'[^a-z0-9 ]', '', string))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HN3uidrMRjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "421d207e-7881-41a6-b625-d626bfeb160b"
      },
      "source": [
        "trial['full'] = Full\n",
        "trial.head(1001)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent</th>\n",
              "      <th>binary</th>\n",
              "      <th>full</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-09-22</th>\n",
              "      <td>electra say criticism activist bramson beggar ...</td>\n",
              "      <td>0</td>\n",
              "      <td>electra say criticism activist bramson beggar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13</th>\n",
              "      <td>britain see return rise say need fresh funcompany</td>\n",
              "      <td>1</td>\n",
              "      <td>electra say criticism activist bramson beggar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-12-11</th>\n",
              "      <td>weaker miner push share five week low</td>\n",
              "      <td>0</td>\n",
              "      <td>electra say criticism activist bramson beggar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-12-18</th>\n",
              "      <td>sncf mull buyout uk government eurostar stake ...</td>\n",
              "      <td>1</td>\n",
              "      <td>electra say criticism activist bramson beggar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-29</th>\n",
              "      <td>uk private equity firm keen sell asset yield h...</td>\n",
              "      <td>1</td>\n",
              "      <td>electra say criticism activist bramson beggar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-07-25</th>\n",
              "      <td>mining share drag share lower company shine</td>\n",
              "      <td>1</td>\n",
              "      <td>uk share lower close trade uk share higher clo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-07-26</th>\n",
              "      <td>de beer size canadian diamond project first bi...</td>\n",
              "      <td>0</td>\n",
              "      <td>uk share higher close trade company tintos min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-07-27</th>\n",
              "      <td>explainer indian billionaire anil agarwals mov...</td>\n",
              "      <td>1</td>\n",
              "      <td>company tintos mineral sancompany operation so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-07-30</th>\n",
              "      <td>share decline u deal boost gvc</td>\n",
              "      <td>1</td>\n",
              "      <td>company share cloud u demancompany congo docum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-01</th>\n",
              "      <td>company investor win billion return asset sale...</td>\n",
              "      <td>0</td>\n",
              "      <td>take five world market theme week ahead compan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1001 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                         sent  ...                                               full\n",
              "Date                                                           ...                                                   \n",
              "2014-09-22  electra say criticism activist bramson beggar ...  ...  electra say criticism activist bramson beggar ...\n",
              "2014-11-13  britain see return rise say need fresh funcompany  ...  electra say criticism activist bramson beggar ...\n",
              "2014-12-11              weaker miner push share five week low  ...  electra say criticism activist bramson beggar ...\n",
              "2014-12-18  sncf mull buyout uk government eurostar stake ...  ...  electra say criticism activist bramson beggar ...\n",
              "2015-01-29  uk private equity firm keen sell asset yield h...  ...  electra say criticism activist bramson beggar ...\n",
              "...                                                       ...  ...                                                ...\n",
              "2018-07-25        mining share drag share lower company shine  ...  uk share lower close trade uk share higher clo...\n",
              "2018-07-26  de beer size canadian diamond project first bi...  ...  uk share higher close trade company tintos min...\n",
              "2018-07-27  explainer indian billionaire anil agarwals mov...  ...  company tintos mineral sancompany operation so...\n",
              "2018-07-30                     share decline u deal boost gvc  ...  company share cloud u demancompany congo docum...\n",
              "2018-08-01  company investor win billion return asset sale...  ...  take five world market theme week ahead compan...\n",
              "\n",
              "[1001 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsj5cRRZMRj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7200e788-109f-4fc9-f25b-81b7a33e5173"
      },
      "source": [
        "print(Full[100])\n",
        "print(sentence[9])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forget bitcoin think high yield share stock supercharge portfolio short seller wouldnt touch share dividend stock thats im buying uk share lower close trade uk share higher close trade uk share higher close trade uk share lower close trade private equity firm post half year return share inch lower drop offset company surge istanbul talk metro funding new mayor visit london source uk share lower close trade infrastructure sell uk project portfolio million\n",
            "share sink lower oil major hit crude price slide\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "objkA7hOOVze",
        "colab_type": "text"
      },
      "source": [
        "# **I will now train BERT to understand the sentiment** \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQfywFcUMRkF",
        "colab_type": "text"
      },
      "source": [
        "From now on I will build a model that models the sentiment, I will use labled financial news articles that have been to train the BERT model and then I will be able to use it on my dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuyMtdndMRkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "85c25b5c-b1e0-467a-e0d5-c0992e95fd85"
      },
      "source": [
        "file = open('drive/My Drive/Sentences_66Agree.txt', 'r', encoding = \"ISO-8859-1\")\n",
        "sentiment = []\n",
        "train_sent = []\n",
        "length = 0\n",
        "for line in file:\n",
        "    line = line.split('@')\n",
        "    sentiment.append(line[1][:-1])\n",
        "    s=re.sub(r'-', ' ',line[0].lower())\n",
        "    s=re.sub(r'[^a-z0-9 ]', '', s) #removing number doesnt do much to improve \n",
        "    words = s.split()\n",
        "    words = [word for word in words if word not in stop_words] #removes stop words\n",
        "    content = ' '.join([lemmatizer.lemmatize(word) for word in words]) #reduces every word to its stem\n",
        "    train_sent.append(content)\n",
        "    length +=1\n",
        "print(len(sentiment))\n",
        "print(len(train_sent))\n",
        "print(sentiment[1])\n",
        "print(train_sent[1200])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4217\n",
            "4217\n",
            "neutral\n",
            "server responsible managing device user account desktop client application enables remote access mobile phone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtUwAEDJMRkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d644a138-0df5-4d95-99e3-eeb91c98f29c"
      },
      "source": [
        "i=0\n",
        "for sent in sentiment:\n",
        "    if sent == 'neutral':\n",
        "        i+=1\n",
        "print(i)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olzm9WfeMRkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e92a57ee-2f0f-4645-8d59-23645605b5a3"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "    \n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ebTkA4AMRkp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689,
          "referenced_widgets": [
            "5034a369a4ff44d2b9761d5130ae32ef",
            "5878da4489ae4bf7ac268087be71611d",
            "a84dcf17e252471faa698c05455f3fab",
            "9909c7d8881d4153ad16884250fca53c",
            "f698124db00b4e50a9175d75d25598b1",
            "8a6bbfba977d4699804537923be80c71",
            "701734365ba54ea592102dba2899d155",
            "7a552b26ec7c43ddac22de8b8f1da4f8"
          ]
        },
        "outputId": "f1239e54-349a-40a6-ccb3-7ba136eecd56"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/25/89050e69ed53c2a3b7f8c67844b3c8339c1192612ba89a172cf85b298948/transformers-3.0.1-py3-none-any.whl (757kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 757kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 13.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 21.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=c8a5f34a8a971bd7cf09917ea256b64972a18b22a93725648bf2d466f1888395\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.1\n",
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5034a369a4ff44d2b9761d5130ae32ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35xbZhVBMRkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = train_sent\n",
        "label = sentiment\n",
        "binary = []\n",
        "\n",
        "for i in sentiment:\n",
        "    if i == 'negative':\n",
        "        binary.append(0)\n",
        "    elif i == 'positive':\n",
        "        binary.append(2)\n",
        "    else:\n",
        "        binary.append(1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgkhhizwMRk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "cb7e6f4a-ab60-43fb-d380-6ccf14538c71"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentence[1000])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentence[1000]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence[1000])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  according finnair technical service measure due employment situation\n",
            "Tokenized:  ['according', 'finn', '##air', 'technical', 'service', 'measure', 'due', 'employment', 'situation']\n",
            "Token IDs:  [2429, 9303, 11215, 4087, 2326, 5468, 2349, 6107, 3663]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFmA3i36MRk8",
        "colab_type": "text"
      },
      "source": [
        "May want to change \"ftse 100\" to \"index\" so its tokenized as one word \n",
        "remove all numbers?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMsrkWhcMRk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8d14f7aa-57aa-468f-b496-afa7e0a31e72"
      },
      "source": [
        "print(type(sentence))\n",
        "print(len(sentence))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "4217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGzdHZ_iMRlE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b1cc8c1-6deb-4cb4-8695-736306b3d241"
      },
      "source": [
        "max_len = 0\n",
        "# For every sentence...\n",
        "for sent in sentence:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYutsiSiMRlL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "286d63c8-a511-4899-bd1a-7193d4916205"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentence:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 50,         # Pad & truncate all sentences.\n",
        "                        truncation = True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(binary)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentence[100])\n",
        "print('Token IDs:', input_ids[100])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  net sale increased eur655m april june 2010 eur438m year earlier\n",
            "Token IDs: tensor([  101,  5658,  5096,  3445,  7327,  2099, 26187,  2629,  2213,  2258,\n",
            "         2238,  2230,  7327,  2099, 23777,  2620,  2213,  2095,  3041,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eLAmaVbMRlT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "79fcf262-c46c-4309-88ae-00e361b32809"
      },
      "source": [
        "#labels = trial.binary.values\n",
        "\n",
        "#labels = torch.tensor(np.array(binary))\n",
        "print(len(input_ids))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Imzt4oUEMRlY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d35cbaa7-4cad-42aa-eb6a-6a2adf115e84"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "print(len(input_ids),len(labels))\n",
        "\n",
        "\n",
        "# Shuffling the data \n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "input_ids, attention_masks, labels = shuffle(input_ids, attention_masks, labels, random_state=0)\n",
        "\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "split = 3000\n",
        "test = 700\n",
        "val = 300\n",
        "train_dataset = TensorDataset(input_ids[:split], attention_masks[:split], labels[:split])\n",
        "val_dataset = TensorDataset(input_ids[split:split + val], attention_masks[split:split + val], labels[split:split + val])\n",
        "test_dataset = TensorDataset(input_ids[split + val:], attention_masks[split + val:], labels[split + val:])\n",
        "# Create a 90-10 train-validation split.\n",
        "print(len(test_dataset))\n",
        "print(labels[:split])\n",
        "\n",
        "p=0\n",
        "n=0\n",
        "neu=0\n",
        "b=0\n",
        "for l in labels[split:split+val]:\n",
        "  if l == 1:\n",
        "    neu+=1\n",
        "  elif l ==0:\n",
        "    n+=1\n",
        "  elif l==2:\n",
        "    p+=1\n",
        "  else:\n",
        "    b+=1\n",
        "print(neu,n,p,b)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4217 4217\n",
            "917\n",
            "tensor([1, 1, 1,  ..., 0, 2, 1])\n",
            "173 52 75 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMgrz1nKMRld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evw4QdXvMRlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = SequentialSampler(train_dataset), # Select batches sequentially\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfpfG2RaMRlz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d014dd1861664a8699e8349fd778585c",
            "776bede1fce4459aa9bbe05c76a93634",
            "c035c3d891174737ad1f41171aa79555",
            "acad3ef1689847e2b462239623585371",
            "8fff9d1960594d6584f92211d329ec71",
            "0ba9d13ce49d4860897ccbfa2ddc0183",
            "0bdaa2aac87d40e5a0623349d3f437f3",
            "cc515bca4643494cbfb7356ef37b4b91",
            "afb2a84a9d5a4a6e98ea4fcf8f41aa6a",
            "aa7723a59d5f461a9f884097395e5bfc",
            "77e50e5f462f4a60b9b43abbb5d9e678",
            "832a4ed2d48d481fb9eb2bd3ac1c04d4",
            "3c2a6dd154924d23ae1dc446e96c3a96",
            "68c1bbb867c54d109b561f664a368d35",
            "b031b41ae48540928f9fcc8edb4678f9",
            "5b9d0a76d54c4cc6b77506351cf3f133"
          ]
        },
        "outputId": "8d9de8e8-2ff2-46df-b5b0-b464eefa0c5b"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d014dd1861664a8699e8349fd778585c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afb2a84a9d5a4a6e98ea4fcf8f41aa6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9-eRN-dMRl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "2d6a51cd-5d52-44e1-df2d-105c069646a8"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukho8KfjMRl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe3ep-g_MRmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZwJKR4rMRmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        },
        "outputId": "b648ad41-b621-482c-f22f-641091d754e9"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     94.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     94.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.79\n",
            "  Training epcoh took: 0:00:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     94.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     94.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.50\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     94.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     94.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.48\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     94.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     94.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.48\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:03:17 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfplfEiJMRmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "376d9506-ef5c-4e37-b7ff-f8b143199a38"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.79</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0:00:47</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:00:48</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:00:48</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:00:48</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.79         0.62           0.75       0:00:47         0:00:02\n",
              "2               0.45         0.50           0.81       0:00:48         0:00:02\n",
              "3               0.28         0.48           0.83       0:00:48         0:00:02\n",
              "4               0.21         0.48           0.83       0:00:48         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8hoZTGmMRmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "dd9896cf-4f64-4f92-dc7c-57d593db0d47"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVF572dpMRmj",
        "colab_type": "text"
      },
      "source": [
        "# Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2gu6F7SMRml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "cellView": "form",
        "outputId": "8eb69ae9-1765-42dc-9abc-1e9093908cab"
      },
      "source": [
        "#@title Default title text\n",
        "import pandas as pd\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-07ccead4d0c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Report the number of sentences.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of test sentences: {:,}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create sentence and label lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U394No8lMRms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "aa9c128a-6dd7-4fc5-fd98-295887b74640"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "prediction_dataloader = DataLoader(\n",
        "            test_dataset,  # The training samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Select batches sequentially\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_dataset)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 917 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x43NL1ZGUUck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0876bee5-1461-4318-88c6-3c6e5b77526b"
      },
      "source": [
        "pred_labels = []\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels.append(np.argmax(predictions[i], axis=1).flatten())\n",
        "\n",
        "pred_labels = np.concatenate(pred_labels)\n",
        "true_labels = np.concatenate(true_labels)\n",
        "\n",
        "for i in range(len(pred_labels)):\n",
        "  if pred_labels[i] == true_labels[i]:\n",
        "    a += 1\n",
        "print('Accuracy : ', a/len(true_labels))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.8516902944383861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpTMSdEs0sln",
        "colab_type": "text"
      },
      "source": [
        "# This model is 85% accurate at understanding the sentement of a finiancial news article "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40-4dpO4MRmv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70cc2cb0-5370-4a96-b5ee-7adb69aff098"
      },
      "source": [
        "#print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A6PcUquMRm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "c04917a9-9c1c-4380-ea06-ec20cab872e9"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqxIrv0xMRm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8681bb6c-7438-4734-9753-60d379c2b5ed"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q365zZjDMRnD",
        "colab_type": "text"
      },
      "source": [
        "# Saving the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sc8xyqDMRnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save_BERT/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opJXeiOeMRnO",
        "colab_type": "text"
      },
      "source": [
        "Cite: Chris McCormick and Nick Ryan. (2019, July 22). BERT Fine-Tuning Tutorial with PyTorch. Retrieved from http://www.mccormickml.com"
      ]
    }
  ]
}